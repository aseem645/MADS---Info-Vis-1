{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Visualization I \n",
    "## School of Information, University of Michigan\n",
    "\n",
    "## Pandas Review\n",
    "This tutorial serves as a brief review of Pandas. There are a few specific transformations we will use in the infovis class. Working through this material (and looking back at past courses should help). Each block of code contains comments that explain the Pandas operations being used. There are a few places where we ask you to try to write some code. There's a button that will pop up with the answers. We have noticed that it doesn't work with some security configurations. If that's the case for you, we've provided a file with all the answers [here](assets/pandas/pandas_tutorial_answers.txt).\n",
    "\n",
    "For this tutorial, we downloaded some health data for you related to e-coli infections from: https://bchi.bigcitieshealth.org/indicators/1859/searches/34539. It's a nice dataset to play with to stretch our Pandas muscles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "exec(open(\"tutorial_helper.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beacd51157134e3282c590017c9ff47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "answerButton(description='show me...', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace the following code to load the file 'assets/pandas/tutorial_data_ecoli_wide.csv'\n",
    "# Call the dataframe df\n",
    "\n",
    "# make the sample ID the index\n",
    "answerButton(\"assets/pandas/e66327e8c15548b0bcdcdadefd3f4e30\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at what's inside. There are a few methods to help..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5) # let's look at the first five lines of the data frame\n",
    "\n",
    "# you'll notice a set of different fields and values... some will be more useful than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # we can find out how many columns and rows we have\n",
    "# first number is rows, second is columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # let's also just get a list of the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can delete rows or columns we don't want\n",
    "\n",
    "`df.drop('dropme',axis=1)` is used to drop the column named dropme. The code `axis=1` tells pandas that we want to drop a column rather than a row (otherwise, we'd use `axis=0`).\n",
    "\n",
    "When you make this call, the code will return a new dataframe, so we'll want to \"grab\" it. We can either create a new dataframe:\n",
    "\n",
    "`df_clean = df.drop(...)` or just overwrite the old one:\n",
    "\n",
    "`df = df.drop(...)`\n",
    "\n",
    "There are a few fields we don't need, specifically: 'Indicator Category', 'Indicator', 'BCHC Requested Methodology', 'Source', 'Methods', 'Notes', '90% Confidence Level - Low', '90% Confidence Level - High', '95% Confidence Level - Low', '95% Confidence Level - High'\n",
    "\n",
    "Delete these and save the result into a new dataframe called `df_clean`. You can do this one at a time or read the documentation to do it all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "answerButton(\"assets/pandas/95365da784604176bf77e1ba86860a0d\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this\n",
    "df_clean = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's work with selecting some rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract given rows of data based on position (row count). iloc is based on the row number\n",
    "df_clean.iloc[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or extract the rows based on index (in this case, they are the same). loc is based on whatever we set the index to\n",
    "# in this case it's Sample ID. This next command says give me everything between sample IDs 395 and 7678\n",
    "df_clean.loc[395:7678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to grab a specific column, we could do the following:\n",
    "df_clean['Place']\n",
    "\n",
    "# This gives us back a \"series\" which is a much more basic dataframe... only a pair of index and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's say we want to pick out data from Texas. There are a few ways of doing that\n",
    "\n",
    "# first thing first, if we run the following:\n",
    "\n",
    "df_clean['Place'] == 'Dallas, TX'\n",
    "\n",
    "# we will get back a series with true/false values corresponding to rows that match our search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanted to get the actual corresponding to this query, we could do:\n",
    "\n",
    "dallas = df_clean[df_clean['Place'] == 'Dallas, TX']\n",
    "dallas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# try to make a new data frame called texas which only has Dallas, Houston, Fort Worth (Tarrant County), \n",
    "# or San Antonio locations. There are (at least) two ways to do it\n",
    "\n",
    "answerButton(\"assets/pandas/f484f6a78f7b40c4aae7fea8684ca0da\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this\n",
    "texas = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by State\n",
    "\n",
    "We want to merge all the cities in a given state into one. The first thing we'll want to do is pull out the last two characters from the Place... this corresponds to the state. You can do this with:\n",
    "\n",
    "`df_clean['Place'].str[-2:]`\n",
    "\n",
    "add a new column to df_clean that contains the state name, call it `State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['State'] = df_clean['Place'].str[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to use groupby to merge all the rows that are for the same state into one row per state/year pair. So for example, if we have data for California that includes \"Long Beach\", \"San Diego\" and \"Los Angeles\" we'd like to make just a single row that has the *mean* of all the e-coli incidents. Note that we could also do the sum or some other aggregation if we wanted. For example, if we wanted to calculate the sum by place we might do:\n",
    "\n",
    "`df_clean.groupby(['Place']).sum()`\n",
    "\n",
    "Try to do this for State and Year (using the mean, not the sum!) and put the new data frame into a table called grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "answerButton(\"assets/pandas/e6b45903889943a993fe65da25b57bb9\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this\n",
    "grouped_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do this, you will notice that the row indices are a little bit wonky (they're group). To reset these we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide to Long\n",
    "\n",
    "At this point the data is in a \"wide format.\"  That is, we have lots of columns (one for each race) for each location/year. \n",
    "\n",
    "<img src=\"assets/pandas/wide.png\" alt=\"wide format table\" width=\"600\">\n",
    "\n",
    "It turns out that the visualization tools we will use do better with data in \"long format.\" In a long format, we create a new row for each year, place, race triplet: \n",
    "\n",
    "<img src=\"assets/pandas/long.png\" alt=\"long format table\" width=\"300\">\n",
    "\n",
    "There are a number of ways to achieve this, but one of the easiest is the pandas \"melt\" function.  The melt function takes the column names on which we want to \"pivot\" the data. In our case, we want to pivot the values from the race columns but keep state and year consistent. So we will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_format = grouped_df.melt(id_vars=['State','Year'])\n",
    "long_format.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we will need to use other transformations (pivots, unstacking, etc.) but those are less common. Review the page at: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a last step, let's clean the data a bit and drop the N/As\n",
    "long_format = long_format.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Let's do a quick sanity check on the data. If we want to find the 5 highest cases we might do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_format.sort_values('value',ascending=False).head(5) #Sorts based on length, ascending order is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also just get lots of summary statistics.\n",
    "long_format.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Time Series\n",
    "\n",
    "The Year column is currently a number, but we may want to transform it into a date so we can easily calculate things like moving averages. Use the pandas `to_datetime` function to transform the year for the long_format table. Because we only have 'Year,' you'll need to use the 'format' argument. We'll just assume any measurement was taken on January 1st of that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "answerButton(\"assets/pandas/23bbcc621003415f8ba401a083ac0348\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this code\n",
    "long_format['Year'] = long_format['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in some cases we'll want to transform numerical data (like year) to a string. This is because some visualization tools will make an *inference* about what you want to display based on the data type. If the year was numerical, the software might assume you want a continuous time series and will draw points or bars for missing years in a way that might not be desirable. \n",
    "\n",
    "Create a column called StringYear that holds the Year as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "answerButton(\"assets/pandas/b70446f2e79a4f34990aecb2c55f54d2\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this\n",
    "long_format['StringYear'] = long_format['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've done this correctly:\n",
    "\n",
    "`long_format['Year'].mean()` will work (but only with Pandas >= .25)\n",
    "\n",
    "`long_format['StringYear'].mean()` will not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning data\n",
    "\n",
    "Let's do a really fast experiment to bin the data by value. \n",
    "\n",
    "`pd.cut(series,bins,labels=...)` is used for this.\n",
    "\n",
    "If we thought we had equal-sized bins, we might generate a range and then use the value of the bin to give a bin label to each value. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'long_format' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-74b12a2bc42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbin_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_format\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbin_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note, we need one less label than binning criteria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# let's add a column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlong_format\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fixedbins'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_format\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbin_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'long_format' is not defined"
     ]
    }
   ],
   "source": [
    "bin_values = np.arange(0.0,100.0,5.0)\n",
    "pd.cut(long_format['value'],bin_values,labels=bin_values[0:-1])  # note, we need one less label than binning criteria\n",
    "\n",
    "# let's add a column\n",
    "long_format['fixedbins'] = pd.cut(long_format['value'],bin_values,labels=bin_values[0:-1])\n",
    "long_format.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the data is very lopsided; Most of the values are really low. So when we ask for the \"counts\" of each bin we get a skewed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_format['fixedbins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, try to bin the values so that we have a \"very low\", \"low\", \"medium\", and \"high\" corresponding to values of 0 to .5, .5 to 1, 1 to 5, and anything higher. Put the bin labels into a \"bin\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "answerButton(\"assets/pandas/f920cd4c3662417abf90a4eff03b60a2\",\"show me...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "long_format['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Frames\n",
    "It is worth reviewing different ways to create dataframes from code (instead of files). There are a number of ways of doing this including reading in dictionaries or making lists. We encourage you to review the documentation on this (easy start: https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an example to make a simple two column data frame\n",
    "\n",
    "data = {'fruit':['apple', 'banana', 'pineapple', 'mango'], 'price':[5, 2, 9, 10]}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to build the same data frame here but we're going to assume the data came to us in \n",
    "# in pieces\n",
    "\n",
    "# we have an array with the first set of fruit and the prices\n",
    "fruit1 = ['apple', 'banana']\n",
    "sales1 = [5,2]\n",
    "\n",
    "# and a second array of tropic fruit\n",
    "tropical = ['pineapple','mango']\n",
    "sales2 = [9,10]\n",
    "\n",
    "# if we think we're going to need three data frames (one for each type of fruit and one that's the whole thing)\n",
    "# we might do:\n",
    "fruit_df = pd.DataFrame(list(zip(fruit1,sales1)), columns=['fruit','price'])\n",
    "tropical_df = pd.DataFrame(list(zip(tropical,sales2)), columns=['fruit','price'])\n",
    "\n",
    "# zip... if you're interested, will make pairs of matched objects (e.g., apple -> 5, banana -> 2) from \n",
    "# arrays... list will transform this into a list data structure that we can use\n",
    "\n",
    "pd.concat([fruit_df,tropical_df]).reset_index(drop=True)\n",
    "\n",
    "# because each table had it's own index we dropped those and created a new one"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "228px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "518px",
    "left": "0px",
    "right": "1207px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "none",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
